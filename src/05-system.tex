\section{Design of \tool}

\begin{figure*}[h]
    \centering
      \includegraphics[width=0.9\textwidth]{figs/prompt.pdf}
    \caption{The system is controlled by a central "controller" with memory storage and validation capabilities. Our controller deploys three key modules: 1) Process Behavior Tree Construction Module, which maps out behavioral patterns; 2) Command Execution Module, which deploys active processes; and 3) Log Constraint Extraction Module, which determines log-based requirements. These units meticulously craft program profiles using LLMs-assisted strategies and traditional methods.}
    \label{fig-framework-prompt}
    \end{figure*}

\subsection{Definitions}

\subsubsection{System Entity and System Event}
We distinguish five principal entity categories: \textit{Processes}, \textit{Files}, \textit{Registry}, \textit{Dynamic Link Libraries (DLLs)}, and \textit{Network Connections}, the latter typically denoted by sockets. System entities possess unique attributes: the attributes associated with /textit[process] entities might include their Process ID (pid) or path to their executables. These entities' relationships and attributes are illustrated in Figure~\ref{fig-entity}. 

Our representation of a system event is given by
\[ e = (src, dst, rel, time) \]
where
\begin{itemize}
    \item \( src \) designates the source entity, constrained to only process entities,
    \item \( dst \) indicates the target or destination entity,
    \item \( rel \) describes their interaction nature, such as a process writing to a file,
    \item \( time \) specifies the timestamp of the event occurrence.
\end{itemize}
We also illustrated the temporal relationship between events as $\langle e_1 \to e_2 \to e_3 \rangle$, indicating that the events occur in a logical sequence. 



\begin{figure}[ht]
    \centering
      \includegraphics[width=0.45\textwidth]{figs/entity.pdf}
    \caption{System Entity and System Event.}
    \label{fig-entity}
\end{figure}

\subsection{Process Classification}

\subsubsection{Process Monitoring}

Process Monitoring is crucial: we need to gather logs from different processes in the system. In order to accomplish this, we use Windows' robust log collection and processing tool, Sysmon, to capture comprehensive system logs. Sysmon's default configuration ensures maximal log collection. 
However, due to the vast amount of logs, it becomes imperative to trim the data down. Using expert knowledge, we remove redundant and mundane events from the logs.

\subsubsection{Noisy Events Reduction}
Due to their inherent granularity and verbosity, audit logs introduce significant noise for analysts.
The omission of certain events does not impact the normal functioning of processes in behavioral cases. Integration of domain knowledge enhances our ability to reduce redundant events. There are also actions that are universal to all processes, such as loading \textit{ntdll.dll}  or \textit{kernel32.dll}. We've streamlined these ubiquitous events for a more concise representation.

\subsubsection{Process Classification}
\label{sec:classifition}
We created a prompt to query the LLMs about whether a particular program exists by name so that the classification could be completed. Using the LLMs' response, we classified these processes into three categories: legitimate process names, illegitimate process names, and uncertain process names (due to the incompleteness of the GPT database). In order to construct the profiles for the processes that fall under the legitimate category, we use the methods that are described in the sections that follow. The latter two categories should be investigated further by security analysts as they are potentially malicious.

\subsection{Profile Construction}
\label{sec:profile_con}
Next, we present our profile building module in detail, which consists of three agent components and a central program controller.
\tool is controlled by a central program controller, which is often referred to as the "brain" of the system. In this brain, two components are integral: memory and validation mechanisms, which include both format and factual verification. 
Format validation of LLMs results can be solved with simple traditional programs.

In order to conduct the factual validation, multiple LLMs sessions are debating each other, as well as real-life logs being validated.
This central program controller controls three distinct agent modules: the Process Behavior Tree Construction Module, the Command Execution Module, and the Log Constraint Extraction Module. Each module manages LLMs sessions and context independently, ensuring both coherence and specialized expertise. It combines LLMs-driven processes (like behavior tree construction) with conventional computational tasks (like frequent sequence mining). A combination of traditional and LLMs-driven processes is used to create detailed process profiles under program controller guidance.

\subsubsection{Process Behavior Tree Construction}
The construction of \textit{Process Behavior Trees} is one of the most important steps in the process.
First, we define the \textit{Process Behavior Tree}.
\begin{figure}[h]
    \centering
    \begin{subfigure}{0.45\textwidth}
      \includegraphics[width=1\textwidth]{figs/tree1.pdf}
      \caption{Process Behavior Tree Representation}
    \end{subfigure}
    \begin{subfigure}{0.45\textwidth}
    \includegraphics[width=1\textwidth]{figs/tree2.pdf}
    \caption{Process Behavior Tree Representation in natural Language}
    \end{subfigure}
    \vspace{-0.05in}
    \caption{In two formats: a) visualized tree format; and b) natural language format encoded in LLMs.}
    \label{fig:behavior-tree}
    \vspace{-0.15in}
    \end{figure}


\begin{definition}[Process Behavior Tree]
A Process Behavior Tree (BT) is a tuple \((N, B)\), where:
\begin{enumerate}
    \item \(N\) is a set of nodes organized in a tree structure. Each node represents legitimate behavior of a process. A node possesses a unique identifier within it, as well as a special node, called the root, which has no parent and does not contain any children. Except for the root of the tree, all nodes have exactly one parent and a zero number of children. There can be a sub-behavior associated with each of these children nodes.
    \item \(B\) is a function that assigns to each node \(n \in N\) a set of attributes \(B(n)\). Each attribute is a pair \((b, w)\), where \(b\) is the behavior name and \(w\) is a description or attribute of that behavior. 
\end{enumerate}
\end{definition}

To generate as many behaviors as possible, we've crafted two prompts: the "Initialization Behavior Tree Prompt" and the "Expansion Behavior Tree Prompt" (A detailed prompt can be found in the Appendix~\ref{prompt-init-tree}). Initially, we employ the Initialization Behavior Tree Prompt to create a foundational behavior tree. Subsequently, this tree is expanded through iterative rounds using the Expansion Behavior Tree Prompt. In order to create a diversity and precision of behaviors, we have incorporated four strategies:
\begin{itemize}
    \item Creating an Initial Process Behavior Tree: To ensure a standardized behavior tree, we've defined a specific output format for the behavior tree.
    \item Different Expansion Techniques in Behavior Tree Prompt: The Behavior Tree Prompt uses two distinct expansion techniques - self-ask and layer-wise. While self-ask aims at a macroscopic expansion of behaviors, layer-wise expansion delves deeper to uncover finer, detailed behaviors. To extract a comprehensive set of behaviors, these two methods combine breadth and depth searches.
    \item Conversation History and Language Learning Models: LLMs often ignore earlier details in a conversation, focusing on recent interactions. As a countermeasure, we leverage the benefits of the system role and embed both roles and objectives within it.
    \item Self-Evaluation by LLMs: We aim to provide LLMs with the ability to self-criticize and review current nodes. If the LLMs determines that the branch does not require expansion, node expansion is stopped.
\end{itemize}

The resulting behavior tree is illustrated in the Figure~\ref{fig:behavior-tree}. Taking the behavior tree of \textit{svchost.exe} as an example, we begin with the basic profile. This includes details such as the execution path of the process, its parent process (the parent process of \textit{svchost.exe} can only be \textit{services.exe}), and its child processes. Following this, we have the fundamental behaviors, such as service hosting, DLL loading, and service isolation exhibited by \textit{svchost.exe}. Focusing on the most significant behavior, which is service hosting, the behavior tree can be extended to detail the specific services being hosted. From the Figure~\ref{fig:behavior-tree}, one can observe the graphical representation of the behavior tree and its expression in natural language.




\subsubsection{Command Execution}

In this step, we design a prompt (detailed prompts can be found in Appendix~\ref{prompt-commands}) for generating commands based on a previous behavior tree. In order to obtain actual log files, this prompt generates corresponding system commands. We can verify some of the behaviors described in the previous step by collecting these logs. Using these logs, it is possible to directly verify some behaviors like parent processes, execution paths, and other details. It is, however, not possible to translate all system processes behaviors into executable commands. In these cases, we employ the LLMs to produce relevant recommendations, which guide us in manually engaging with the system to obtain the required logs.

\subsubsection{Constraint Extraction}

\begin{figure*}[h]
  \begin{subfigure}{.5\textwidth}
      \includegraphics[width=\textwidth]{figs/svchost_constraints.pdf}
      \caption{Constraints of Svchost}
      \label{fig:cons-svchost}
  \end{subfigure}
  \hfill
  \begin{subfigure}{.5\textwidth}
      \includegraphics[width=\textwidth]{figs/smss_lsass_constraints.pdf}
      \caption{Constraints of Smss and Lsass}
      \label{fig:cons-smss-lsass}
  \end{subfigure}

  \begin{subfigure}{.5\textwidth}
      \includegraphics[width=\textwidth]{figs/svchost.pdf}
      \caption{Svchost Constraints in Graph format}
      \label{fig:con-svchost-tree}
  \end{subfigure}
  \hfill
  \begin{subfigure}{.5\textwidth}
      \includegraphics[width=\textwidth]{figs/lsass.pdf}
      \caption{Lsass Constraints in Graph format}
      \label{fig:con-lsass}
  \end{subfigure}
  \caption{Constraint Definition}
  \label{fig:cons-def}
 \end{figure*}


The extraction of system constraints is a pivotal step in our methodology. We begin by categorizing constraints into five types as shown in Figure~\ref{fig:cons-def}.
The Figure~\ref{fig:cons-def} illustrates the constraints of three processes: svchost.exe, lsass.exe, and smss.exe. In Figure~\ref{fig:cons-svchost}, the constraints of svchost.exe are shown. There are five types of constraints: execution path, parent process, child process, intrinsic constraints (svchost.exe will always load kernel32.dll and advapi32.dll.), and temporal constraints (advapi32.dll, msvct.dll, and kernelbase.dll must be loaded in the specified sequence).
For certain processes, like smss.exe, parent and child processes are optional. The parent process of smss.exe can be system.exe or Ntoskml.exe.
In summary, these constraint relationships can be fully characterized using the AND, OR, and ORDER operators.

By comparing them with the logs gathered in the previous steps, we can verify and extract the first three constraints directly.
However, for intrinsic and temporal constraints, the challenge arises due to real-world logs' vastness. It is impractical to query the LLMs for each log due to memory constraints and its propensity to forget extended conversations. To overcome this, we designed a hybrid method that combines traditional programming techniques with queries to the LLMs to extract these two constraints.

To clearly describe the common items and frequent sequence mining algorithms, we first provide some definitions.
Given a set of log sequences \( \mathcal{D} \), each sequence \( S \in \mathcal{D} \) contains logs \( L \), where each log is a tuple \( L = (s, o, d,t) \) consisting of:
\begin{align*}
    s & : \text{Source process} \\
    o & : \text{Operation} \\
    d & : \text{Destination or object of the operation}\\
    t & : \text{time specifies the timestamp of the event occurrence}
\end{align*}

We are trying to find frequent subsequences \( \mathcal{F} \) exceeding a threshold \( \theta \), here \( \theta =1\), indicating items that should occur frequently
We begin by mining the logs for common items among different log sequences in order to speed up frequent item mining. Our next step is to use the PrefixSpan algorithm to find frequent subsequences in these logs.
(Algorithms are detailed in the Appendix~\ref{alg:fre-common}).
Having established the common items and sequences, we then direct our queries towards the LLMs, focusing specifically on these elements to extract intrinsic and temporal constraints. Furthermore, we request the LLMs to explain its findings, providing insights into these constraints.
The detailed set of prompts used in this process as shown in Appendix~\ref{prompt-cons-explain}.



\subsubsection{Validation}
Due to the potential for hallucinations or misleading results, it is imperative to ensure the accuracy and consistency of LLMs outputs. Due to this challenge, we developed a two-dimensional validation system.

\textbf{Format Validation.}
As a result of this initial step, the model's output adheres to a predefined structure. Using conventional programming methods, deviations are corrected to match the expected format.

\textbf{Factual Validation.}
A more important verification is the factual validation, which is designed to ensure that LLM's final output is accurate and consistent.

\begin{itemize}
    \item Real-world Cross-referencing: LLMs outputs are executed as real-world commands, and their results are cross-checked against real-world logs.
    \item LLMs Multi-session Debates: The LLMs engages in iterative debates in multiple instances. Their goal is to find a consensus on an answer that is both accurate and reliable by verifying each other's responses and reasoning. They cannot reach a consensus on actions that are not entirely correct by having multiple LLMs debate each other. For definitive behaviors, they can eventually come to an agreement. A more detailed description of our approach can be found in the Appendix~\ref{prompt-cross-validation}.
\end{itemize}



\subsection{Threat Detection}
\label{sec:Threat_detection}

This is the basis of our offline process for building individual process profiles. An initial query is made to LLMs in order to determine whether processes with obfuscated or random names exist online. The process is likely to be malicious if it does not exist. Our established methodology allows us to profile processes that exist but are not in our knowledge base.

An anomaly detection process is based on a multitude of rules derived from the preceding steps. In various attacks, these rules are specifically designed to pinpoint the exact constraints that have been violated. Process masquerading, for example, violates execution pathway and parent-child constraints, whereas process injection violates inherent and temporal constraints more often.

\textbf{Construction Unseen Process Profile.}
Observing whether profile incompletion occurs in a sandbox environment helps prevent profile incompletion. This method may reduce false alarms for benign interactions between system entities that were not observed during profile construction.