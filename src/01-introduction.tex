%-------------------------------------------------------------------------------
\section{Introduction}
%-------------------------------------------------------------------------------
Advanced Persistent Threats (APTs) have emerged as a formidable adversary in the cyber landscape. Their stealthy, persistent nature, coupled with the extensive damage they can inflict, make them exceptionally challenging to detect and mitigate. 
In light of this, we embarked on an exhaustive study of current commercial Endpoint Detection and Response (EDR) products \cite{karantzas2021empirical} and provenance graph-based solutions \cite{cheng2023kairos,alsaheel2021atlas,han2020unicorn,inam2022sok,han2021sigl}. Our deep dive into these systems allowed us to identify critical gaps and challenges. Specifically, we distilled the problems facing current solutions into four key dimensions:

\begin{itemize}
    \item \textbf{Insufficient information within Log Data}: Effective intrusion detection hinges on the richness and comprehensiveness of audit logs. Recent research \cite{gandhi2023rethinking} underscores a concerning deficiency: current logging systems capture insufficient information for reliable attack detection. Solely relying on these raw logs may result in a low attack detection coverage. To further enhance this capability, we aim to detect more attacks without increasing the granularity of log collection. A need exists to integrate more detailed knowledge into our system, especially in understanding the precise meanings of entities within logs, including process names, registry files and dynamic link libraries (DLLs), etc. By enriching our logs with more information and knowledge, we stand a better chance of detecting a wider range of attacks, especially the stealthy behaviors often employed in APT attacks.
    \item \textbf{Attack Agnosticity}: 
    Zero-day vulnerabilities (malware or flaws not yet identified by security analysts), especially in APT attacks, require detection systems that are not bound by pre-existing signatures or indicators. Anomaly detection \cite{wang2020you, alsaheel2021atlas, han2020unicorn}, stands out as the most effective technique for identifying such zero-day exploits. Therefore, an optimal method of detecting these unknown threats would not rely on known attack patterns.
    \item \textbf{Evolving Threats}: Advanced Persistent Threats (APT) represent dynamic, sustained, and sophisticated threats. Professional attacker groups continuously innovate, targeting an ever-expanding array of system processes and adapting to the latest defensive measures. This evolving landscape necessitates detection methods that can swiftly identify and adapt to emerging attack paradigms.
    \item \textbf{Transparency}: The value of detection alerts lies in their clarity. For security personnel, a clear understanding of the 'why' and 'how' behind detection can drive quicker and more effective interventions. By providing clear explanations, system administrators will have a better understanding of the threat landscape, allowing them to respond to threats faster and in a more knowledgeable manner.
\end{itemize}

While data provenance-based threat detection has emerged as a promising approach against the covert Advanced Persistent Threats (APTs), current methodologies exhibit specific shortcomings, failing to satisfy all four dimensions concurrently.
% \yd{YD: Maybe can merge the following content into above four key dimensions?}
Commercial products designed to detect APT attacks, along with \textbf{misuse-based} APT research \cite{milajerdi2019holmes,milajerdi2019poirot,hossain2020combating}, predominantly hinge on rules defined by security experts. While these misuse-oriented strategies excel at identifying known threats, they lack flexibility when confronted with novel, undefined threats. Consequently, they are constrained by predefined security policies, struggling to swiftly track evolving attacks.
On the other hand, while \textbf{anomaly-based} techniques \cite{wang2022threatrace,han2020unicorn,wang2020you} are adept at spotting deviations, their outcomes often lack transparency and pose challenges for integration into commercial products. Within this realm, graph \cite{manzoor2016fast,han2020unicorn,li2021hierarchical,yang2023prographer,cheng2023kairos} and path-based methods \cite{wang2020you,alsaheel2021atlas} tend to detect only those attacks that leave discernible traces on the graph or path, yielding results that are too macroscopic. Node-based methods provide finer granularity but can sometimes oversimplify intricate attack behaviors. 
Knowledge graph embedding techniques\cite{zeng2021watson,zengy2022shadewatcher} may have difficulty representing a single process accurately with a single vector due to the diversity of node functions and similarities between normal nodes and malicious nodes.
\textbf{Statistical-based} techniques \cite{liu2018towards,hassan2019nodoze,hassan2020we}, although intuitive, grapple with false positives, making it tough to differentiate genuinely anomalous behaviors from benign novelties. 
In sum, while each technique offers nuanced advantages, a comprehensive method that addresses all four dimensions and seamlessly tackles every facet of APT detection remains an open challenge.


The primary impediments to addressing the current challenges in APT detection can be attributed to the inherently knowledge-intensive nature of the cybersecurity domain. When faced with audit logs that present insufficient information, there's an acute need to augment them with supplementary domain-specific knowledge. This supplemental knowledge becomes even more crucial when attacks evolve or present themselves in stealthy manners. Moreover, a well-rounded domain understanding also serves as a basis for explaining detection results, enhancing transparency for security analysts. Thus, the key to overcoming these challenges lies in the ability to swiftly and effectively harness extensive cybersecurity knowledge.
Fortunately, Large Language Models (LLMs) have demonstrated remarkable prowess in recent years. These models are capable of understanding human-like text intricacies and have demonstrated efficacy across a wide range of domains, especially those requiring rapid knowledge extraction. There is an important question here: \textit{Can LLMs be effectively leveraged in cybersecurity to improve detection methods for stealthy and evolving APT attacks?}

In response to this crucial question, we focus on addressing these dimensions, combining knowledge extraction prowess of LLMs with the structural expertise of provenance graphs, aiming to detect APT. To accomplish our goal, we want the LLMs to automatically identify key constraints associated with system processes. These constraints are then transformed into actionable rules that serve as vital tools for detecting attacks. It is possible to detect attacks without increasing the granularity of our log data by thoroughly extracting and understanding log entities, such as program names, dynamic link libraries (DLLs), and registers. In addition, LLMs' vast knowledge repository allows us to discover unknown and evolving threats in addition to interpreting the nature of the attacks. As a result, we cover the four dimensions previously discussed.

As we all known, the use of LLMs for contract process profiling has both advantages and challenges. It is evident that LLMs have extensive knowledge of process behavior and are able to explain their outputs. However, following detailed practice, we found that LLMs construction processes presented challenges due to  \textit{difficulty handling complex scenarios}, 
\textit{context reliance}, \textit{memory limitations}, and \textit{the possibility of generating inaccurate information or hallucinations}.

To address these challenges, we introduced ProfileGuard, a method for automated system process profile construction using LLMs.This method involves:

\begin{itemize}
    \item Process Behavior Tree Construction: We attempted to capture as many behaviors as possible for each process, creating a behavior tree. Using a "self-ask" approach, the LLMs continuously expanded its knowledge of this tree. This tree also played a pivotal role in providing the LLMs with contextual depth.
    \item Command Execution: Based on the behavior tree, the LLMs scripted and executed commands for relevant behaviors. 
    \item Constraint Extraction: We designed a hybrid method that combines traditional programming techniques With queries to the LLMs to extract different process constraints. 
    \item Validation: A two-tiered validation approach has been implemented to validate the model's outputs. In the first tier, we execute actual commands and verify them against real-world logs, followed by a multi-round debate among the LLMs to validate their responses and reasoning.
\end{itemize}
We will delve into the mechanics of our design in detail in Section~\ref{sec:motivation}.


By using C++ and Caldera, we were able to comprehensively simulate various aspects of APT attacks. Based on existing APT attack documentation, we simulated 10 APT attack scenarios incorporating four prevalent stealth techniques, 23 malicious functionalities, and 4 prevalent stealth techniques. In the process of building 100 profiles for critical system processes, we spent approximately an hour and \$3.5 per profile. Further, we collected malware used in known APT attacks from public repositories and websites, revealing that camouflage techniques are ubiquitous in such attacks.
As a result, the detection rates and range of threats identified by ProCon were consistently superior to those of existing solutions. With our realistic and multifaceted attack simulations, ProCon's robust performance accentuates its transformative potential in cybersecurity, offering organizations a stronger defense against APT threats.


